{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of gastiadi_coba.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "TfCqBk0pwGH8",
        "v1LUR9y8wGID",
        "fRa0RPlCwGIE",
        "mW4H0ZmPwGIG",
        "PsDQe8QuwGIH",
        "hgzCZ3VzwGII",
        "1K0TUVTSwGIJ",
        "x3HhDZP9wGIJ",
        "XuH9Ck0iwGIK",
        "fHyJ6JcfwGIM",
        "51lOLBfSwGIN",
        "nXQUGl2owGIQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-1Q7M2hwGHe"
      },
      "source": [
        "# GASTIADI PROJECT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwSxCavjKu9N"
      },
      "source": [
        "### Install the required packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6lKIEkIcD7W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Pehn8ScFXH"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import RandomState\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqF2OBBZwGHh"
      },
      "source": [
        "### Prep work: Downloading necessary files\n",
        "Before we get started, we need to store all of the data we'll be using.\n",
        "* **sentiment500-subset.csv:** cleaned subset of Sentiment1000 data - as positive or negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyiyYGKqeA3"
      },
      "source": [
        "import the data in session storage and then copy the path of each data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yk2gSJuDnFU"
      },
      "source": [
        "dataset = ('/content/datset_fix.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUZ31WkgwGHk"
      },
      "source": [
        "dataset= pd.read_csv(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTg4YhUU4UsW"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk1SsXehNHhu"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2rDO6nC4Dp"
      },
      "source": [
        "print((dataset.Label == 1).sum()) #urgent\n",
        "print((dataset.Label == 0).sum()) #unurgent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryFctP4JEcP9"
      },
      "source": [
        "dataset.Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EXI8w1gEf3b"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Count Unique Word\n",
        "\n",
        "def counter_word(text_col):\n",
        "    count = Counter()\n",
        "    for text in text_col.values:\n",
        "        for word in text.split():\n",
        "            count[word]+=1\n",
        "    return count\n",
        "  \n",
        "counter = counter_word(dataset.Text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMrZALNGFFBo"
      },
      "source": [
        "len(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpkQeZMTwOCN"
      },
      "source": [
        "#Split Dataset Into Training and Validation Set\n",
        "import numpy\n",
        "train_size = int(dataset.shape[0]*0.8)\n",
        "\n",
        "train_ds = dataset[:train_size]\n",
        "val_ds = dataset[train_size:]\n",
        "\n",
        "#Split Text and Label\n",
        "train_sentences = train_ds.Text.to_numpy()\n",
        "train_labels = train_ds.Label.to_numpy()\n",
        "val_sentences = val_ds.Text.to_numpy()\n",
        "val_labels = val_ds.Label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SryKeuDaHGKN"
      },
      "source": [
        "train_sentences.shape, val_sentences.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH_QhZgak1lc"
      },
      "source": [
        "#Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vectorize a text corpus by turning each text into a sequence of integers\n",
        "num_unique_words=len(counter)\n",
        "tokenizer = Tokenizer(num_words=num_unique_words)\n",
        "tokenizer.fit_on_texts(train_sentences) #fit only to training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWu2qeCAwbGB"
      },
      "source": [
        "#each word has uniwue index\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQyTdeOIS4A"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNQIsmEFOdVJ"
      },
      "source": [
        "train_sentences=tokenizer.texts_to_sequences(train_sentences)\n",
        "val_sentences=tokenizer.texts_to_sequences(val_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ao5DKn-vkNQ"
      },
      "source": [
        "print(train_sentences[10:15])\n",
        "print(val_sentences[10:15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huOz2xsLxKgu"
      },
      "source": [
        "#Pad the sequences to have the same length\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Max number of words in a sequence\n",
        "max_length = 20\n",
        "\n",
        "train_padded =pad_sequences(train_sentences, maxlen=max_length, padding='post',truncating='post')\n",
        "val_padded =pad_sequences(val_sentences, maxlen=max_length, padding='post',truncating='post')\n",
        "train_padded.shape , val_padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV9Z_1LxX8_"
      },
      "source": [
        "#Check the padding\n",
        "train_padded[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgLqVksbqYqx"
      },
      "source": [
        "#Create Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
        "model.add(layers.LSTM(64, activation='relu', dropout=0.1))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3--uQO7OAZw"
      },
      "source": [
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "optim = keras.optimizers.Adam(lr=0.01)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(loss= loss, optimizer=optim, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudXov_0PPdy"
      },
      "source": [
        "history = model.fit(train_padded, train_labels,epochs =20, validation_data=(val_padded,val_labels),verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhnJD_oQMO0e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "  \n",
        "print(plot_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwEYZ_BrgDjz"
      },
      "source": [
        "model.evaluate(train_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V16ZSW_lavWS"
      },
      "source": [
        "predictions = model.predict(train_padded)\n",
        "predictions = [1 if p> 0.5 else 0 for p in predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWPNkdVsbEwH"
      },
      "source": [
        "print(train_sentences[10:20])\n",
        "\n",
        "print(train_labels[10:20])\n",
        "print(predictions[10:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G7ANIoer6XX"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#Fitting model with trainig data\n",
        "regressor.fit(train_padded, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLnM3mYnu6g"
      },
      "source": [
        "model.save(\"gastiadi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfCqBk0pwGH8"
      },
      "source": [
        "### Predicting with our models\n",
        "\n",
        "To make a prediction for each of our sentences, you can use `.predict` with each of our models. For example, it would look like this for linear regression:\n",
        "\n",
        "```python\n",
        "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
        "```\n",
        "\n",
        "To add the prediction for logistic regression, you'd run similar `.predict` code, which will give you a `0` (negative) or a `1` (positive). A difference between the two is that for logistic regression, you can **also ask for the probability that the sentence is in the `1` category** instead of just simply the category. To do that, you use this code:\n",
        "\n",
        "```python\n",
        "unknown['pred_logreg_prob'] = linreg.predict_proba(unknown_words_df)[:,1]\n",
        "```\n",
        "\n",
        "**Add new columns for each of the models you trained.** If the model has a `.predict_proba`, add that as a column as well. \n",
        "\n",
        "* **Tip:** Tab is helpful for knowing whether `.predict_proba` is an option.\n",
        "* **Tip:** Don't forget the `[:,1]` after `.predict_proba`, it means \"give me the probability for category `1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQygN3b3wGH9"
      },
      "source": [
        "# Predict using all our models. \n",
        "\n",
        "# Logistic Regression predictions + probabilities\n",
        "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
        "unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]\n",
        "\n",
        "# Random forest predictions + probabilities\n",
        "unknown['pred_forest'] = forest.predict(unknown_words_df)\n",
        "unknown['pred_forest_proba'] = forest.predict_proba(unknown_words_df)[:,1]\n",
        "\n",
        "# SVC predictions\n",
        "unknown['pred_svc'] = svc.predict(unknown_words_df)\n",
        "\n",
        "# Bayes predictions + probabilities\n",
        "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
        "unknown['pred_bayes_proba'] = bayes.predict_proba(unknown_words_df)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmI0weVTwGH9"
      },
      "source": [
        "unknown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3bvMnZwGH_"
      },
      "source": [
        "## Testing our models\n",
        "\n",
        "We can actually see **which model performs the best!** Remember how we trained our models on tweets? We can ask each model about each tweet, and see if it gets the right answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL1RlcOMwGIA"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqqNARmowGIB"
      },
      "source": [
        "Our original dataframe is a list of many, many tweets. We turned this into `X` - vectorized words - and `y` - whether the tweet is negative or positive.\n",
        "\n",
        "Before we used `.fit(X, y)` to train on all of our data. Instead, **we can test our models** by doing a test/train split and see if the predictions match the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waeJjTxmwGIC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1LUR9y8wGID"
      },
      "source": [
        "### Confusion matrices\n",
        "\n",
        "To see how well they did, we'll use a [\"confusion matrix\"](https://en.wikipedia.org/wiki/Confusion_matrix) for each one. I think confusion matrices are called that because they are confusing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_-M4e14wGIE"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRa0RPlCwGIE"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY4SQmhOwGIF"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4H0ZmPwGIG"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUpCgrdAwGIG"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsDQe8QuwGIH"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYN4Gt8swGIH"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzCZ3VzwGII"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HppSoZzLwGII"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K0TUVTSwGIJ"
      },
      "source": [
        "### Percentage-based confusion matrices\n",
        "\n",
        "Those are kind of irritating in that they're just numbers. Let's try percentages instead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3HhDZP9wGIJ"
      },
      "source": [
        "#### Logisitic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GISgUq_VwGIK"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuH9Ck0iwGIK"
      },
      "source": [
        "#### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgFJza2fwGIL"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHyJ6JcfwGIM"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpivqyXwGIM"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51lOLBfSwGIN"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHtTSypGwGIO"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQUGl2owGIQ"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WqfO2x1wGIR"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}